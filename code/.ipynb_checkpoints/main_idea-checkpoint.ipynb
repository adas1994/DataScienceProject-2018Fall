{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "##dimenional reduction methods\n",
    "##implement performing methods,store vectors pipline\n",
    "\n",
    "#implement by Yifan\n",
    "#1.SVD\n",
    "#2.PCA\n",
    "\n",
    "#by Adas(drawing)\n",
    "#1.MDS\n",
    "#2.Laplace Eigenmap\n",
    "#3.LLE(hessian LLE saved)\n",
    "#4.isomap\n",
    "\n",
    "#by Adas(not drawing)\n",
    "#1.TSNE\n",
    "\n",
    "#supply by Yifan\n",
    "#1.LDA(labelled by group)\n",
    "\n",
    "#AD\n",
    "#1.one-layer linear\n",
    "#2.one-layer non-linear\n",
    "    #activation function= Relu+Relu\n",
    "    #activation function=Relu+Sigmoild\n",
    "#3.5-layer\n",
    "#4.look at the Yan-Lecun hyperparameter selection of auto encoder\n",
    "\n",
    "##in-situ evaluation\n",
    "# SVD/PCA draw the first 30 singular_values/eigen_value to see how it decreases.\n",
    "#Loss function for all the methods(some methods may have pre-pocessing, may not be consistant)\n",
    "\n",
    "#key file of function\n",
    "\n",
    "##getting the element-environment pairwise matrix\n",
    "###1.getting the chemical formula\n",
    "###2.do the cleanning process\n",
    "###3.build the element-environment pairwise matrix from the cleaned data\n",
    "\n",
    "##building element vector by different methods\n",
    "###1.linear methods-PCA,SVD\n",
    "###2.several non-linear method: LLE, Laplance_eigen_map, Isomap, TSNE, (LDA), MDS\n",
    "###3.auto encoder (1 layer linear/non-linear), several layers\n",
    "\n",
    "##evaluation\n",
    "###1.elapslite formation energy(main group)\n",
    "####Method 1: a.build vectors of each compound. b.use a model(two layers, 10-hold out method),get average MAE.\n",
    "####Method 2??:build another formula-> EEPM, test!\n",
    "\n",
    "###2.color map\n",
    "####Method 1: a.draw the vector in 2D map b.PCA drawing the first 2 components\n",
    "####Method 2: change ethod 1: 1st-> hirachical clustering 2nd->t-SNE\n",
    "\n",
    "###3.element property\n",
    "####Method 1: linear regression/one layer NN to predict atomic number, raw number, column number(classification task)\n",
    "####Method 2: Electronegativity(Allen or Pauling)\n",
    "\n",
    "###4.provosket formation energy(all group)\n",
    "####Method 1: a.build vectors of each compound. b.use a model(two layers, 10-hold out method),get average MAE."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "##evaluation method 1-element numerical property : atomic_number(raw_number, column_number), \n",
    "##ele_negativity_allen, ele_negativity_pauling\n",
    "\n",
    "#train/validation/test split, error examination"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "##evaluation method 2-2D mapping for element vector(PCA/t-SNE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "##evaluation method 3-formation energy(elapsite?,provosket?)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "#should do L2 normalization for data_matrix at the axis=1\n",
    "#dimensions reduction methods: PCA,MDS,LDA(n different categories),isomap,LLE,\n",
    "#t-SNE(not good for 2-3dimension),but can be utilized to visualization\n",
    "#Auto encoder, Yann-Lecun paper to talk about how to adjust hyper parameter(layer,activiation function, filter size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "#import needed package\n",
    "from sklearn.metrics.pairwise import euclidean_distances as ed\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.manifold import MDS,TSNE,SpectralEmbedding,LocallyLinearEmbedding,Isomap\n",
    "import pandas as pd\n",
    "import re"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "#needed dataset path\n",
    "pair_matrix_path=\"../data_set/element_pair_matrix/first_Matrix_09_13_2018.csv\"\n",
    "main_element_path=\"../data_set/element_list/elements_list_main.txt\"\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "#import element-envrionment pairwise matrix\n",
    "dataframe = pd.read_csv(pair_matrix_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_matrix = dataframe.values\n",
    "elements = np.asarray(data_matrix[:,0]).astype(str)\n",
    "data_matrix_raw = data_matrix[:,1:].astype(float)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "#do normalization of data_matrix_raw\n",
    "from sklearn.preprocessing import normalize\n",
    "data_matrix_nor=normalize(data_matrix_raw, norm='l2', axis=1, copy=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "##perfrom PCA, store the resulting 30 vectors in file\n",
    "##this process on CRC\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "##perform Laplace Eigenmap\n",
    "#Converting Raw Sparse Vectors to 20 and 30 dimensional embeddings using Laplace Eigenmap\n",
    "embedding_20dim = SpectralEmbedding(n_components=20)\n",
    "embedding_30dim = SpectralEmbedding(n_components=30)\n",
    "x_transformed1 = embedding_20dim.fit_transform(data_matrix_nor)\n",
    "x_transformed2 = embedding_30dim.fit_transform(data_matrix_nor)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "'SpectralEmbedding' object has no attribute 'reconstruction_error_'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-53-3e847f26c073>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0membedding_20dim\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreconstruction_error_\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m: 'SpectralEmbedding' object has no attribute 'reconstruction_error_'"
     ]
    }
   ],
   "source": [
    "embedding_20dim.reconstruction_error_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "##perform Laplace Eigenmap continued.\n",
    "laplace_eigenmap_path=\"../data_set/element_vector_generation/laplace_eigenmap/\"\n",
    "laplace_name_1=\"laplace_eigenmap_20.txt\"\n",
    "laplace_name_2=\"laplace_eigenmap_30.txt\"\n",
    "\n",
    "np.savetxt(laplace_eigenmap_path+laplace_name_1,x_transformed1)\n",
    "np.savetxt(laplace_eigenmap_path+laplace_name_2,x_transformed2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": [
    "##perform Laplace Eigenmap continued. by adas\n",
    "laplace_eigenmap_path=\"../data_set/element_vector_generation/laplace_eigenmap/\"\n",
    "laplace_name_adas=\"laplace_eigenmap_adas.txt\"\n",
    "embedding_adas = SpectralEmbedding(n_components=20,n_neighbors=4)\n",
    "x_transformed_adas = embedding_adas.fit_transform(data_matrix_nor)\n",
    "np.savetxt(laplace_eigenmap_path+laplace_name_adas,x_transformed_adas)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "#perform LLE ‘standard’, ‘hessian’, ‘modified’ or ‘ltsa’)\n",
    "#standard LLE default setting except n_components=20\n",
    "\n",
    "\n",
    "#hessian LLE is not achievable\n",
    "#n_neighbors > [n_components * (n_components + 3) / 2] can not fit\n",
    "#LLE_H=LocallyLinearEmbedding(n_components=20,method='hessian')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "LLE = LocallyLinearEmbedding(n_neighbors=10,n_components=20,method='standard')\n",
    "LLE_path=\"../data_set/element_vector_generation/LLE/\"\n",
    "n_neighbors=10\n",
    "LLE_name_1=\"LLE_component10_neighbor10.txt\"\n",
    "LLE_transformed = LLE.fit_transform(data_matrix_nor)\n",
    "np.savetxt(LLE_path+LLE_name_1,LLE_transformed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "#perform MDS\n",
    "mds = MDS(n_components=20)\n",
    "mds_transformed = mds.fit_transform(data_matrix_nor)\n",
    "\n",
    "mds_path=\"../data_set/element_vector_generation/MDS/\"\n",
    "mds_name_1=\"mds.txt\"\n",
    "np.savetxt(mds_path+mds_name_1,mds_transformed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#embedding_2d = TSNE(n_components=20,perplexity=50)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
